{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 케라스를 사용한 인공 신경망 소개\n",
    "인공 신경망: 뇌에 있는 생물학적 뉴런의 네트워크에서 영감을 받은 머신러닝 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 생물학적 뉴런에서 인공 뉴런까지\n",
    "- 인공 신경망이 우리 생활에 훨씬 커다란 영향을 줄 것이라는 근거:\n",
    "    - 신경망을 훈련하기 위한 데이터가 엄청나게 많아짐.\n",
    "    - 1990년대 이후 컴퓨터 하드웨어가 크게 발전했고, 납득할 만한 시간 안에 대규모 신경망을 훈련할 수 있음.\n",
    "    - 훈련 알고리즘이 향상됨\n",
    "    - 일부 인공 신경망의 이론상 제한이 실전에서는 문제가 되짐 않음\n",
    "    - 인공 신경망이 투자와 진보의 선순환에 들어간 것으로 보임.\n",
    "\n",
    "### 10.1.1 생물학적 뉴런\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](https://github.com/oony97/Hands-On-Machine-Learning/blob/main/%EA%B7%B8%EB%A6%BC10_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수상돌기 <-> 축삭돌기 <-> 축삭끝가지 <-> 시냅스 말단 (시냅스) <br>\n",
    "- 활동 전위 또는 신호라고 부른 짧은 전기 자극은 축삭 돌기를 따라 이동하여 신경전달물질이라는 화학적 신호를 발생."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 뉴런을 사용한 논리 연산\n",
    "인공 뉴런: 하나 이상의 이진(on/off) 입력과 이진 출력 하나를 가진다. 입력이 일정 개수만큼 활성화되었을 때 출력을 내보냄.\n",
    "![nn](그림10_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.3 퍼셉트론\n",
    "- 퍼셉트론: 입력과 출력이 이진값이 아닌 어떤 숫자이고, 각각의 입력 연결은 가중치와 연관되어 있음.\n",
    "    - Threshold logic unit (TLU) 또는 linear threshold unit (LTU) 라고 불리는 인공 뉴런을 기반으로 함\n",
    "    - TLU는 입력된 가중치의 합을 계산($z = w_{1}x_{1}+ \\cdots + w_{n}x_{n} = x^{T}w$)한 뒤 계산된 합에 계단 함수를 적용하여 결과를 출력 \n",
    "    - $h_{w}(x) = step(z), z = x^{T}w$\n",
    "- 헤비사이드 계단 함수\n",
    "![nn](식10_1.png)\n",
    "- 퍼셉트론은 층이 하나뿐이 TLU로 구성되고, 각 TLU는 모든 입력에 연결되어 있음.\n",
    "- 완전 연결 층 (밀집 층): 한 층에 있는 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때\n",
    "- 퍼셉트론의 입력은 입력 뉴런에 주입 됨. 입력층은 모두 입력 뉴런으로 구성되고 보통 거기에 편향 특성이 더해짐 ($x_{0}=1$).\n",
    "![nn](그림10_5.png)\n",
    "- 완전 연결 층의 출력 계산: $$h_{w,b}(X) = \\phi(XW + b)$$\n",
    "- 헤브의 규칙 (헤브 학습): 두 뉴런이 동시에 활성화될 때마다 이들 사이의 연결 가중치가 증가한다.\n",
    "    - 퍼셉트론에 한 번에 한 개의 샘플이 주입되면 각 샘플에 대해 예측이 만들어지고, 잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 가중치를 강화\n",
    "- 퍼셉트론 수렴 이론: 훈련 샘플이 선형적으로 구분될 수 있다면 퍼셉트론이 정답에 수렴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다층 퍼셉트론 (MLP): 퍼셉트론을 여러 개 쌓아올려 일부 제약을 줄인 것.\n",
    "![nn](그림10_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.4 다층 퍼셉트론과 역전파\n",
    "- 다층 퍼셉트론은 입력층 하나와 은닉층이라 불리는 하나 이상의 TLU층과 마지막 출력층으로 구성. 입력층과 가까운 층은 하위 층, 출력에 가까운 층은 상위층.\n",
    "- 출력층을 제외하고 모든 층은 편향 뉴런을 포함\n",
    "![nn](그림10_7.png)\n",
    "- 심층 신경망: 은닉층을 여러 개 쌓아 올린 인공 신경망\n",
    "- 역전파: 그레이디언트를 자동으로 계산하는 경사 하강법\n",
    "    - 네트워크를 두 번 (정방향 한 번, 역방향 한 번) 통과하는 것만으로 이 역전파 알고리즘은 모든 모델 파라미터에 대한 네트워크 오차의 그레이디언트를 계산할 수 있음\n",
    "    - 그레이디언트를 구하면 평범한 경사 하강법을 수행.\n",
    "    - 전체 과정을 네트워크가 어떤 해결책으로 수렴될때까지 반복\n",
    "    - 요약: 각 훈련 샘플에 대해 역전파 알고리즘이 먼저 예측을 만들고 (정방향 계산) 오차를 측정. 다음 역방향으로 각 층을 거치면서 각 연결이 오차에 기여한 정도를 측정 (역방향 계산). 마지막으로 이 오차가 감소하도록 가중치를 조정 (경사 하강법 단계).\n",
    "    - 계단 함수를 활성화 함수로 바꿔야 하는 이유: \n",
    "        - 선형 변환을 여러개 연결해도 얻을 수 있는 것은 선형 변환뿐 => 층 사이에 비선형성을 추가하지 않으면 아무리 층을 많이 쌓아도 하나의 층과 동일해짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.5 회귀를 위한 다층 퍼셉트론\n",
    "- 다층 퍼셉트론은 회귀 작업에 사용할 수 있음. 출력 차원마다 출력 뉴런이 하나씩 필요함.\n",
    "- 훈련에 사용하는 손실 함수는 전형적으로 평균 제곱 오차. 만약 훈련 세트에 이상치가 많다면 대신 평균 절댓값 오차를 사용할 수 있음. 또는 이 둘을 조합한 후버 손실을 사용할 수 있음.\n",
    "![nn](표10_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.6 분류를 위한 다층 퍼셉트론\n",
    "- 다층 퍼셉트론은 분류 작업에도 사용할 수 있다. 이진 분류 문제에서는 로지스특 활성화 함수를 가진 하나의 출력 뉴런만 필요하다.\n",
    "- 다층 퍼셉트론은 다중 레이블 이진 분류 문제를 쉽게 처리할 수 있다.\n",
    "- 다중 분류:\n",
    "    - 각 샘플이 3개 이상의 클래스 중 한 클래스에만 속할 수 있다면 클래스마다 하나의 출력 뉴런이 필요함.\n",
    "    - 출력층에는 소프트맥스 활성화 함수를 사용하야함. 소프트맥스 함수는 모든 예측 확률을 0과 1 사이로 만들고 더했을 때 1이 되도록 만듬.\n",
    "    ![nn](그림10_9.png)\n",
    "- 확률 분포를 예측해야 하므로 손실 함수에서는 일반적으로 크로스 엔트로피 손실 (로그 손실)을 선택하는 것이 좋음.\n",
    "![nn](표10_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 케라스로 다층 퍼셉트론 구현하기\n",
    "### 10.2.1 텐서플로 2 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기\n",
    "#### 케라스를 사용하여 데이터셋 적재하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 7s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀셜 API를 사용하여 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x28018443848>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x28018456088>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x280184562c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x28018456588>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01893706,  0.06197916, -0.06132386, ..., -0.04399704,\n",
       "        -0.02035479,  0.06976464],\n",
       "       [-0.07289302, -0.03280786,  0.05668417, ...,  0.0131845 ,\n",
       "         0.04346466,  0.03793192],\n",
       "       [ 0.04449257, -0.04020647, -0.06508201, ...,  0.03415182,\n",
       "        -0.05178201, -0.00123457],\n",
       "       ...,\n",
       "       [-0.00633249,  0.02440718, -0.02611518, ...,  0.05153213,\n",
       "         0.07169506,  0.02421561],\n",
       "       [-0.06650162, -0.02004172,  0.05906242, ...,  0.05961077,\n",
       "        -0.07224289, -0.0372232 ],\n",
       "       [ 0.01771439, -0.05123925, -0.03537576, ..., -0.06583031,\n",
       "        -0.05956098,  0.03444682]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일\n",
    "- 모델을 만들고 나서 `comile()` 메서드를 호출하여 사용할 손실 함수와 옵티마이저를 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련과 평가\n",
    "- `fit()` 메서드 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7112 - accuracy: 0.7660 - val_loss: 0.5170 - val_accuracy: 0.8288\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4898 - accuracy: 0.8299 - val_loss: 0.4858 - val_accuracy: 0.8232\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4437 - accuracy: 0.8447 - val_loss: 0.4041 - val_accuracy: 0.8628\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4161 - accuracy: 0.8528 - val_loss: 0.4095 - val_accuracy: 0.8636\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3973 - accuracy: 0.8615 - val_loss: 0.3971 - val_accuracy: 0.8592\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3812 - accuracy: 0.8660 - val_loss: 0.3895 - val_accuracy: 0.8662\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3680 - accuracy: 0.8713 - val_loss: 0.3728 - val_accuracy: 0.8700\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3555 - accuracy: 0.8737 - val_loss: 0.3569 - val_accuracy: 0.8742\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3473 - accuracy: 0.8764 - val_loss: 0.3623 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3379 - accuracy: 0.8787 - val_loss: 0.3794 - val_accuracy: 0.8648\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3294 - accuracy: 0.8829 - val_loss: 0.3362 - val_accuracy: 0.8824\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3213 - accuracy: 0.8846 - val_loss: 0.3278 - val_accuracy: 0.8844\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3130 - accuracy: 0.8865 - val_loss: 0.3303 - val_accuracy: 0.8822\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3069 - accuracy: 0.8905 - val_loss: 0.3250 - val_accuracy: 0.8844\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3003 - accuracy: 0.8918 - val_loss: 0.3283 - val_accuracy: 0.8824\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2946 - accuracy: 0.8945 - val_loss: 0.3188 - val_accuracy: 0.8864\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2877 - accuracy: 0.8964 - val_loss: 0.3128 - val_accuracy: 0.8886\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2831 - accuracy: 0.8978 - val_loss: 0.3134 - val_accuracy: 0.8862\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2763 - accuracy: 0.9000 - val_loss: 0.3210 - val_accuracy: 0.8838\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2720 - accuracy: 0.9019 - val_loss: 0.3136 - val_accuracy: 0.8898\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2674 - accuracy: 0.9029 - val_loss: 0.3223 - val_accuracy: 0.8850\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2620 - accuracy: 0.9055 - val_loss: 0.3093 - val_accuracy: 0.8904\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2577 - accuracy: 0.9064 - val_loss: 0.3002 - val_accuracy: 0.8914\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2537 - accuracy: 0.9077 - val_loss: 0.3042 - val_accuracy: 0.8912\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2487 - accuracy: 0.9097 - val_loss: 0.3067 - val_accuracy: 0.8898\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2447 - accuracy: 0.9115 - val_loss: 0.2921 - val_accuracy: 0.8990\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2411 - accuracy: 0.9124 - val_loss: 0.3009 - val_accuracy: 0.8882\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2372 - accuracy: 0.9146 - val_loss: 0.3090 - val_accuracy: 0.8880\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2343 - accuracy: 0.9145 - val_loss: 0.2958 - val_accuracy: 0.8930\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2287 - accuracy: 0.9174 - val_loss: 0.2982 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 손실은 에포크가 끝난 후에 계산되고 훈련 손실은 에포크가 진행되는 동안 계산됨 => 훈련 곡선은 에포크의 절반만큼 왼쪽으로 이동해야 됨\n",
    "- 모델 성능이 만족스럽지 않으면 하이퍼파라미터를 튜닝.\n",
    "    - 맨 처음 확인할 것은 학습률\n",
    "    - 학습률이 도움이 되지 않으면 다른 옵티마이저를 테스트\n",
    "    - 여전히 성능이 높지 않으면 모델의 하이퍼파라미터(층 개수, 층에 있는 뉴런 개수, 은닉층이 사용하는 활성화 함수)를 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3268277049064636, 0.8842999935150146]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일반화 오차 추정\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델을 사용해 예측을 만들기\n",
    "- 모델의 `predict()` 메서드를 사용해 새로운 샘플에 대해 예측을 만들 수 있다.\n",
    "- 각 샘플에 대해 클래스마다 각각의 확률을 모델이 추정\n",
    "- `predict_class()` 메서드를 사용해 가장 높은 확률을 가진 클래스를 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3 시퀀셜 API를 사용하여 회구용 다층 퍼셉트론 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3360 - val_loss: 0.5899\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5819 - val_loss: 0.5204\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5051 - val_loss: 0.5053\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4811\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.4693\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4553\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4356\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4247\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4196\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4254\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4014\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3911 - val_loss: 0.4057\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3912\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3930\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.4219\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.4000\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4163\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3796\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3909\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4023\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3583\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4 함수형 API를 사용해 복잡한 모델 만들기\n",
    "- 와이드 & 딥 신경망\n",
    "    - 순차적이지 않은 신경망의 예\n",
    "    - 입력의 일부 또는 전체가 출력층에 바로 연결됨\n",
    "    - 이 구조를 사용하면 신경망이 (깊게 쌓은 층을 사용한) 복잡한 패턴과 (짧은 경로로 사용한) 간단한 규칙을 모두 학습할 수 있음.\n",
    "![nn](그림10_14.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6790 - val_loss: 1.1246\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9083 - val_loss: 0.7992\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7502 - val_loss: 0.7285\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7021 - val_loss: 0.6940\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6730 - val_loss: 0.6687\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6515 - val_loss: 0.6485\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6336 - val_loss: 0.6323\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6182 - val_loss: 0.6167\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6050 - val_loss: 0.6058\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5930 - val_loss: 0.5929\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5825 - val_loss: 0.5822\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 0.5753\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5643 - val_loss: 0.5661\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5570 - val_loss: 0.5583\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5496 - val_loss: 0.5504\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5435 - val_loss: 0.5455\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5377 - val_loss: 0.5395\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5340\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5288\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.5276\n",
      "162/162 [==============================] - 0s 819us/step - loss: 0.4997\n"
     ]
    }
   ],
   "source": [
    "# 일부 특성은 짧은 경로로 전달하고 다른 특성들은 (중복 가능) 깊은 경로로 전달\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](그림10_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 출력이 필요한 경우:\n",
    "    - 여러 출력이 필요한 작업. (e.g., 회구 작업과 분류 작업을 함께 하는 경우)\n",
    "    - 동일한 데이터에서 독립적인 여러 작업을 수행 (e.g., 다중 작업 분류)\n",
    "    - 규제 기법으로 사용하는 경우. (즉, 과대적합을 감소하고 모델의 일반화 성능을 높이도록 훈련에 제약을 가함)\n",
    "    \n",
    "![nn](그림10_16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층까지는 이전과 동일\n",
    "output = keras.layers.Dense(1, name=\"main_out\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "# 각 출력은 자신만의 손실 함수 필요\n",
    "# 보조 출력보다 주 출력에 더 관심이 많다면, 주 출력의 손시에 더 많은 가중치 부여\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weigths=[0.9, 0.1], optimizer=\"sgd\")\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "\n",
    "# 모델을 평가하면 개별 손실과 총 손실을 함께 반환\n",
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "\n",
    "# predict() 메서드는 각 출력에 대한 예측 반환\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2.5 서브클래싱 API로 동적 모델 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 예제는 함수형 API와 매우 비슷하지만 Input 클래스의 객체를 만들 필요가 없다.\n",
    "- 대신 `call()` 메서드의 `input` 매개변수를 사용.\n",
    "- `call()` 메서드 안에서 원하는 어떤 계산도 사용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.6 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀셜 API와 함수형 API를 사용하여 훈려된 케ㄹ스 모델 저장하기\n",
    "model = keras.models.Sequential([...])\n",
    "model.comile([...])\n",
    "model.fit([...])\n",
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스는 HDF5 포멧을 사용하여 (모든 층의 하이퍼파라미터를 포함하여) 모델 구조와 층의 모든 모델 파라미터(연결 가중치와 편향)를 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.7 콜백 사용하기\n",
    "- `fit()` 메서드의 `callbacks` 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체 리스트를 지정할 수 있음.\n",
    "- `ModelCheckpoint`는 훈련하는 동안 일정한 간격으로 모델을 체크포인트를 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[...] # 모델을 만들고 컴파일하기\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callback=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ModelCheckpoint를 만들 때 save_best_only=True로 지정하면 최상의 검증 세트 점수에서만 모델을 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 종료 구현 방법\n",
    "checkpoint_cb = keras.callbacks.ModelCHeckpoint(\"my_keras_model.h5\",\n",
    "                                                save_best_only_Treu)\n",
    "history = model.fity(X_train, y_train, epochs=10,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EarlyStopping 콜백 사용하여 조기 종료 구현 가능.\n",
    "- 일정 에포크 동안 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  retore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용자 정의 콜백\n",
    "    - 다음과 같은 사용자 정의 콜백은 훈련하는 동안 검증 손실과 훈련 손실의 비율을 출력 (과대적합 감지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.8 텐서보드를 사용해 시각화하기\n",
    "- 텐서보드 로그를 위해 사용할 루트 로그 디렉터리 정의.\n",
    "- 현재 날짜와 시간을 사용해 실행할 때마다 다른 서브디렉터리 경로를 생성하는 간단한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[...] # 모델 구성과 컴파일\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `TensorBoard()` 콜백이 로그 디렉터리를 생성하고, 훈련하는 동안 이벤트 파일을 만들고 서머리를 기록."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 신경망 하이퍼파라미터 튜닝하기\n",
    "- 주어진 문제에 최적인 하이퍼파라미터 조함 찾기\n",
    "    - 많은 하이퍼파라미터 조합을 시도해보고 어떤 것이 검증 세트에서 가장 좋은 점수를 내는 지 확인 (`GridSearchCV`나 `RandomizedSearchCV` 사용)\n",
    "    - 하이퍼파라미터가 많으므로 그리드 탐색보다 랜덤 탐색을 사용하는 것이 좋음.\n",
    "- 효율적으로 하이퍼파라미터 공간을 탐색하는 기법:\n",
    "    - Hyperopt: 모든 종류의 복잡한 탐색 공간에 대해 최적화를 수행할 수 있는 잘 알려진 라이브러리\n",
    "    - Hyperas, kopt, Talos: 케라스 모델을 위한 하이퍼파라미터 최적화 라이브러리\n",
    "    - 케러스 튜너: 사용하기 쉬운 케라스 하이퍼파라미터 최적화 라이브러리.\n",
    "    - Scikit-Optimize(skopt): 범용 최적화 라이브러리\n",
    "    - Spearmint: 베이즈 최적화 라이브러리\n",
    "    - Hyperband: 빠른 하이퍼파라미터 튜닝 라이브러리\n",
    "    - Sklearn-Deap: GridSearchCV와 비슷한 인터페이스를 가진 진화 알고리즘 기반의 하이퍼파라미터 최적화 라이브러리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 은닉층 개수\n",
    "- 복잡한 문제에서는 심층 신경망이 얕은 신경망보다 파라미터 효율성이 훨씬 좋다.\n",
    "    - 심층 신경망은 복잡한 함수를 모델링하는데 얕은 신경망보다 훨씬 적은 수의 뉴런을 사용하므로 동일한 양의 훈련 데이터에서 더 높은 성능을 낼 수 있다.\n",
    "- 전이 학습: 첫 번째 네트워크 하위 층을 재사용하여 훈련 시작 => 저수준 구조를 학습할 필요가 없음 => 고수준 구조만 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 은닉층의 뉴런 개수\n",
    "- 입력층과 출력층의 뉴런 개수는 해당 작업에 필요한 입력과 출력의 형태에 따라 결정.\n",
    "- 대부분의 경우 모든 은닉층에 같은 뉴런 개수를 사용해도 동일하거나 더 나은 성능 보임.\n",
    "- 필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택하고, 그런 다음 과대적합되지 않도록 조기 종료나 규제 기법을 사용하는 것이 간단하고 효과적.\n",
    "- 한 층의 뉴런 수가 너무 적으면 입력에 있는 유용한 정보를 모두 유지하기 위한 충분한 표현 능력을 가지지 못함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터\n",
    "- 학습률:\n",
    "    - 일반적으로 최적의 학습률은 최대 학습률의 절반 정도.\n",
    "    - 좋은 학습률을 찾는 한 가지 방법은 매우 낮은 학습률에서 시작해서 점진적으로 매우 큰 학습률까지 수백 번 반복하여 모델을 훈련하는 것.\n",
    "    - 최적의 학습률은 손실이 다시 상증하는 지점보다 조금 아래에 있음.\n",
    "- 옵티마이저:\n",
    "- 배치 크기:\n",
    "    - 배치 크기는 모델 성능과 훈련 시간에 큰 영향을 미칠 수 있음.\n",
    "    - 큰 배치 크기를 사용하는 것의 주용 장점을 GPU와 같은 하드웨어 가속기를 효율적으로 활용할 수 있다는 점 => 훈련 알고리즘이 초당 더 많은 샘플을 처리할 수 있음.\n",
    "    - 많은 연구자들과 기술자들은 GPU 램에 맞는 가장 큰 배치 크기를 사용하길 권장.\n",
    "    - 하지만 큰 배치를 사용한 결과 모델은 작은 배치 크기로 훈련된 모델만큼 일반화 성능을 내지 못할 수 있음.\n",
    "- 활성화 함수:\n",
    "     - 일반적으로 ReLU 활성화 함수가 모든 은닉층에 좋은 기본값.\n",
    "     - 출력층의 활성화 함수는 수행하는 작업에 따라 달라짐.\n",
    "- 반복 횟수:\n",
    "    - 대부분의 경우 훈련 반복 횟수는 튜닝할 필요가 없음. 대신 조기 종료 사용.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "774950339c587ca9f62d5b99430caf26f939018233a2ad762310c7ae7196a066"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('hands_on_ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
