{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Training Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "$\\theta$: parameter vector\n",
    "\n",
    "Linear Regression model prediction: $\\hat{y} = \\theta_{0} + \\theta_{1}x_{1} + \\cdots + \\theta_{n}x_{n} = h_{\\theta}(x) = \\theta \\cdot x$ \n",
    "\n",
    "\n",
    "*MSE cost function for Linear Regression model*: $MSE(X, h_{\\theta}) = \\frac{1}{m} + \\sum \\limits _{i=1}^{n}X_{j}(\\theta^{T}x^{(i)}-y^{(i)})^{2}$\n",
    "\n",
    "*Normal Equation*:  $\\hat{\\theta} = (x^{T}X)^{-1}X^{T}y$\n",
    "\n",
    "The computational complexity of inverting a matrix is very high. \\\n",
    "Singular Value Decomposition (SVD): $O(n^{2})$ \n",
    " \n",
    "Predictions are very fast with a Linear Regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "Gradient descent measures the local gradient of the error function with regards to the parameter vector $\\theta$ until the gradient becomes zero. \\\n",
    "=> It reached a minimum (cost function). \\\n",
    "Learning rate: the size of the steps. (Low learning rate => many iterations => takes long time) (too high => bad as well) \\\n",
    "Local minimum, plateau \\\n",
    "The MSE cost function for a Linear Regression model is a *convex function*. => Just one global minimum. \\\n",
    "It is also a continuous function. \\\n",
    "=> guaranteed to approach arbitrarily close the global minimum \n",
    "\n",
    "### Batch Gradient Descent\n",
    "- Partial Derivative of the cost function: how much the cost function will change if you change $\\theta_{j}$\n",
    "- Gradient vector of the cost function: contains all the partial derivatives of the cost function. $\\nabla_{\\theta}MSE(\\theta)$\n",
    "- Gradient Descent step: $\\theta^{(next step)} = \\theta - \\eta\\nabla_{\\theta}MSE(\\theta)$ ($\\eta$: learning rate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "Stochastic Gradient Descent just picks a random instance in the training set at every step and computes the gradients based only on that single instance. \\\n",
    "Over time it will end up very close to the minimum, but once it gets there it will\n",
    "continue to bounce around, never settling down. \\\n",
    "Therefore randomness is good to escape from local optima, but bad because it means that the algorithm can never settle at the minimum. \\\n",
    "One solution to this dilemma is to gradually reduce the learning rate. \\\n",
    "Learning schedule: the function that determines the learning rate at each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch Gradient Descent\n",
    "At each step, Minibatch GD computes the gradients on small random sets of instances called minibatches. \\\n",
    "You can get a performance boost from hardware optimization of matrix operations, especially when using GPUs. (why better than Stochastic GD) \\\n",
    "Mini-batch GD will end up walking around a bit closer to the minimum than SGD. But, on the other hand, it may be harder for it to escape from local minima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "Adding powers of each feature as new features, then train a linear model on this extended set of features. \\\n",
    "PolynomialFeatures also adds all combinations of features up to the given degree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "Learning curve: a plot of the model’s performance on the training set and the validation set as a function of the training set size \\\n",
    "A model’s generalization error can be expressed as the sum of three errors:\n",
    "1. Bias: due to wrong assumptions\n",
    "2. Variance: due to the model’s excessive sensitivity to small variations in the training data\n",
    "3. Irreducible error: due to the noisiness of the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Linear Models\n",
    "A good way to reduce overfitting is to regularize the model. \\\n",
    "For a linear model, regularization is typically achieved by constraining the weights of the model. \\\n",
    "### Ridge Regression\n",
    "A regularized term ($\\sum \\limits _{i=1}^{n}\\theta_{i}^{2}$) is added to the cost function. \\\n",
    "Ridge Regression cost function: $J(\\theta) = MSE(\\theta) + \\alpha \\frac{1}{2} \\sum \\limits _{i=1}^{n}\\theta_{i}^{2}$ \\\n",
    "Ridge Regression closed-form solution: $\\hat{\\theta} = (X^{T}X + \\alpha A)^{-1}X^{T}y$\n",
    "### Lasso Regression\n",
    "Lasso Regression cost function: $J(\\theta) = MSE(\\theta) + \\alpha \\sum \\limits _{i=1}^{n}|\\theta_{i}|$ \\\n",
    "Lasso Regression tends to completely eliminate the weights of the least important features.\n",
    "### Elastic Net\n",
    "The regularization term is a simple mix of both Ridge and Lasso’s regularization terms, and you can control the mix ratio r. \\\n",
    "When r = 0, Elastic Net is equivalent to Ridge Regression, and when r = 1, it is equivalent to Lasso Regression.\\\n",
    "Elastic Net cost fuction: $J(\\theta) = MSE(\\theta) + r\\alpha \\sum \\limits _{i=1}^{n}|\\theta_{i}| + \\frac{1 - r}{2} \\alpha \\sum \\limits _{i=1}^{n}\\theta_{i}^{2}$\n",
    "### Early Stopping\n",
    "Stop training as soon as the validation error reaches a minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is commonly used to estimate the probability that an instance belongs to a particular class. \\\n",
    "### Estimating Probabilities\n",
    "Logistic Regression model estimated probability: $\\hat{p} = h_{\\theta}(x) = \\sigma(x^{T}\\theta)$ \\\n",
    "Logistic Function: $\\sigma(t) = \\frac{1}{1+exp(-t)}$ \\\n",
    "Logistic Regression model prediction: $\\hat{y} = 0$, if $\\hat{p} < 0.5$ and $\\hat{y} = 1$, if $\\hat{p} \\geq 0.5$\n",
    "### Training and Cost Function\n",
    "### Decision Boundaries\n",
    "### Softmax Regression\n",
    "The Logistic Regression model can be generalized to support multiple classes directly. \\\n",
    "When given an instance x, the Softmax Regression model first computes a score sk(x) for each class k, then estimates the probability of each class by applying the softmax function. \\\n",
    "Softmax score for class k: $s_{k}(x)=x^{T}\\theta^{k}$ \\\n",
    "Softmax function: $p_{k} = \\sigma(s(x))_{k}=\\frac{exp(s_{k}(x))}{\\sum \\limits_{j=1}^{K}exp(s_{j}(x))}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
